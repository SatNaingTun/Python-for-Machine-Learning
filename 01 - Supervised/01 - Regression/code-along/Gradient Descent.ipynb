{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[1, 1], [2, 2], [2, 9], [1, 14]])\n",
    "X_train.shape #m, n\n",
    "\n",
    "y_train = np.array([3, 4, 10, 13])\n",
    "y_train.shape #m, \n",
    "\n",
    "X_val = np.array([[1.5, 2], [2, 3], [1, 9], [1, 13]])\n",
    "X_val.shape #m, n\n",
    "\n",
    "y_val = np.array([3, 4, 9.5, 13.5])\n",
    "y_val.shape #m, \n",
    "\n",
    "X_test = np.array([[2, 1], [1, 2], [2, 8], [2, 13]])\n",
    "X_test.shape #m, n\n",
    "\n",
    "y_test = np.array([2, 5, 9, 14])\n",
    "y_test.shape #m, \n",
    "\n",
    "# assert X_train.shape[1] == X_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling\n",
    "\n",
    "Imagine you do:\n",
    "1. imputation - cleaning\n",
    "2. scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for definitions\n",
    "m_train, n_train = X_train.shape\n",
    "m_val, n_val     = X_val.shape\n",
    "m_test, n_test   = X_test.shape\n",
    "num_epochs       = 50\n",
    "theta            = np.zeros(  (n_train,   )  )\n",
    "lr               = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(yhat, ytrue):\n",
    "    return ( (yhat - ytrue) ** 2  ).sum() / yhat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  : train_loss=73.500 : val_loss=64.652\n",
      "Epoch: 2  : train_loss=63.614 : val_loss=56.237\n",
      "Epoch: 3  : train_loss=55.096 : val_loss=48.952\n",
      "Epoch: 4  : train_loss=47.755 : val_loss=42.644\n",
      "Epoch: 5  : train_loss=41.428 : val_loss=37.180\n"
     ]
    }
   ],
   "source": [
    "#1. loop according to epoch\n",
    "for i in range(num_epochs):  #0, 1, 2, 3, 4\n",
    "    \n",
    "    #2. predict\n",
    "    yhat_train = X_train @ theta # (m, n) x (n, 1) = (m, 1)  #<---same shape as y \n",
    "    \n",
    "    #3. gradient\n",
    "    #X^T (h - y)\n",
    "    grad = (X_train.T @ (yhat_train - y_train) ) / m_train  #(n, m) @ (m, 1) = (n, 1)\n",
    "    \n",
    "    #4. update\n",
    "    theta = theta - lr * grad  # (n, 1) - (1) (n, 1) = (n, 1)\n",
    "    \n",
    "    train_loss =  mse(yhat_train, y_train)\n",
    "\n",
    "    #validation loss\n",
    "    #1. take the current theta, and do prediction with the validation set\n",
    "    yhat_val = X_val @ theta\n",
    "    #2. calculate the loss with y_val\n",
    "    val_loss = mse(yhat_val, y_val)\n",
    "    #3. finish\n",
    "    \n",
    "    #########early stopping###################\n",
    "    #1. if new val_loss is very close to old val_loss by 0.001, you stop everything ok!\n",
    "    #2. otherwise continue\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch: {i+1}  : {train_loss=:.3f} : {val_loss=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04865122, 0.30637593])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse=40.35\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/chaklam/Github/Machine-Learning/01 - Supervised/01 - Regression/code-along/Gradient Descent.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chaklam/Github/Machine-Learning/01%20-%20Supervised/01%20-%20Regression/code-along/Gradient%20Descent.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mse       \u001b[39m=\u001b[39m mse(  yhat_test , y_test  )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chaklam/Github/Machine-Learning/01%20-%20Supervised/01%20-%20Regression/code-along/Gradient%20Descent.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmse\u001b[39m=:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chaklam/Github/Machine-Learning/01%20-%20Supervised/01%20-%20Regression/code-along/Gradient%20Descent.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39massert\u001b[39;00m mse \u001b[39m>\u001b[39m \u001b[39m100\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "yhat_test = X_test @ theta\n",
    "mse       = mse(  yhat_test , y_test  )\n",
    "print(f\"{mse=:.2f}\")\n",
    "\n",
    "assert mse > 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0], y_train[0], X_train[1], y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. randomly create a sample\n",
    "chaky_test_case = np.array([ [1.5, 0.5] ])\n",
    "assert len(chaky_test_case.shape) == 2  #m, n\n",
    "\n",
    "#2. predict\n",
    "predict_chaky_test_case = chaky_test_case @ theta\n",
    "predict_chaky_test_case_int = float(predict_chaky_test_case)\n",
    "print(f\"Answer:  {predict_chaky_test_case_int: .2f}.  Does it satisfy you?\")\n",
    "\n",
    "#3. check with your instinct / ask expert whether is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume you have standardize your feature\n",
    "#feature 2 is more important\n",
    "    # 0.30 / (0.04 + 0.30)\n",
    "    \n",
    "#feature 1 is less important\n",
    "    # 0.04 / (0.04 + 0.030)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
