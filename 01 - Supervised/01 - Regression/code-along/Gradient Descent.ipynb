{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[1, 1], [2, 2], [2, 9], [1, 14]])\n",
    "X_train.shape #m, n\n",
    "\n",
    "y_train = np.array([3, 4, 10, 13])\n",
    "y_train.shape #m, \n",
    "\n",
    "X_val = np.array([[1.5, 2], [2, 3], [1, 9], [1, 13]])\n",
    "X_val.shape #m, n\n",
    "\n",
    "y_val = np.array([3, 4, 9.5, 13.5])\n",
    "y_val.shape #m, \n",
    "\n",
    "X_test = np.array([[2, 1], [1, 2], [2, 8], [2, 13]])\n",
    "X_test.shape #m, n\n",
    "\n",
    "y_test = np.array([2, 5, 9, 14])\n",
    "y_test.shape #m, \n",
    "\n",
    "# assert X_train.shape[1] == X_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling\n",
    "\n",
    "Imagine you do:\n",
    "1. imputation - cleaning\n",
    "2. scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for definitions\n",
    "m_train, n_train = X_train.shape\n",
    "m_val, n_val     = X_val.shape\n",
    "m_test, n_test   = X_test.shape\n",
    "num_epochs       = 50\n",
    "theta            = np.zeros(  (n_train,   )  )\n",
    "lr               = 0.001\n",
    "old_val_loss     = np.infty\n",
    "tolerance        = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(yhat, ytrue):\n",
    "    return ( (yhat - ytrue) ** 2  ).sum() / yhat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  : train_loss=73.500 : val_loss=64.652\n",
      "Epoch: 2  : train_loss=63.614 : val_loss=56.237\n",
      "Epoch: 3  : train_loss=55.096 : val_loss=48.952\n",
      "Epoch: 4  : train_loss=47.755 : val_loss=42.644\n",
      "Epoch: 5  : train_loss=41.428 : val_loss=37.180\n",
      "Epoch: 6  : train_loss=35.977 : val_loss=32.444\n",
      "Epoch: 7  : train_loss=31.278 : val_loss=28.338\n",
      "Epoch: 8  : train_loss=27.229 : val_loss=24.777\n",
      "Epoch: 9  : train_loss=23.740 : val_loss=21.687\n",
      "Epoch: 10  : train_loss=20.732 : val_loss=19.004\n",
      "Epoch: 11  : train_loss=18.140 : val_loss=16.673\n",
      "Epoch: 12  : train_loss=15.906 : val_loss=14.648\n",
      "Epoch: 13  : train_loss=13.980 : val_loss=12.886\n",
      "Epoch: 14  : train_loss=12.320 : val_loss=11.354\n",
      "Epoch: 15  : train_loss=10.889 : val_loss=10.019\n",
      "Epoch: 16  : train_loss=9.656 : val_loss=8.856\n",
      "Epoch: 17  : train_loss=8.592 : val_loss=7.842\n",
      "Epoch: 18  : train_loss=7.675 : val_loss=6.956\n",
      "Epoch: 19  : train_loss=6.884 : val_loss=6.183\n",
      "Epoch: 20  : train_loss=6.202 : val_loss=5.507\n",
      "Epoch: 21  : train_loss=5.614 : val_loss=4.916\n",
      "Epoch: 22  : train_loss=5.106 : val_loss=4.398\n",
      "Epoch: 23  : train_loss=4.668 : val_loss=3.944\n",
      "Epoch: 24  : train_loss=4.290 : val_loss=3.546\n",
      "Epoch: 25  : train_loss=3.964 : val_loss=3.196\n",
      "Epoch: 26  : train_loss=3.682 : val_loss=2.888\n",
      "Epoch: 27  : train_loss=3.439 : val_loss=2.617\n",
      "Epoch: 28  : train_loss=3.228 : val_loss=2.377\n",
      "Epoch: 29  : train_loss=3.046 : val_loss=2.166\n",
      "Epoch: 30  : train_loss=2.889 : val_loss=1.980\n",
      "Epoch: 31  : train_loss=2.753 : val_loss=1.815\n",
      "Epoch: 32  : train_loss=2.635 : val_loss=1.669\n",
      "Epoch: 33  : train_loss=2.533 : val_loss=1.539\n",
      "Epoch: 34  : train_loss=2.444 : val_loss=1.423\n",
      "Epoch: 35  : train_loss=2.367 : val_loss=1.321\n",
      "Epoch: 36  : train_loss=2.300 : val_loss=1.229\n",
      "Epoch: 37  : train_loss=2.242 : val_loss=1.147\n",
      "Epoch: 38  : train_loss=2.191 : val_loss=1.074\n",
      "Epoch: 39  : train_loss=2.147 : val_loss=1.009\n",
      "Epoch: 40  : train_loss=2.108 : val_loss=0.950\n",
      "Epoch: 41  : train_loss=2.074 : val_loss=0.897\n",
      "Epoch: 42  : train_loss=2.044 : val_loss=0.850\n",
      "Epoch: 43  : train_loss=2.018 : val_loss=0.807\n",
      "Epoch: 44  : train_loss=1.995 : val_loss=0.768\n",
      "Epoch: 45  : train_loss=1.974 : val_loss=0.734\n",
      "Epoch: 46  : train_loss=1.956 : val_loss=0.702\n",
      "Epoch: 47  : train_loss=1.940 : val_loss=0.673\n",
      "Epoch: 48  : train_loss=1.925 : val_loss=0.647\n",
      "Epoch: 49  : train_loss=1.912 : val_loss=0.624\n",
      "Epoch: 50  : train_loss=1.900 : val_loss=0.602\n"
     ]
    }
   ],
   "source": [
    "#1. loop according to epoch\n",
    "for i in range(num_epochs):  #0, 1, 2, 3, 4\n",
    "    \n",
    "    #2. predict\n",
    "    yhat_train = X_train @ theta # (m, n) x (n, 1) = (m, 1)  #<---same shape as y \n",
    "    \n",
    "    #3. gradient\n",
    "    #X^T (h - y)\n",
    "    grad = (X_train.T @ (yhat_train - y_train) ) / m_train  #(n, m) @ (m, 1) = (n, 1)\n",
    "    \n",
    "    #4. update\n",
    "    theta = theta - lr * grad  # (n, 1) - (1) (n, 1) = (n, 1)\n",
    "    \n",
    "    train_loss =  mse(yhat_train, y_train)\n",
    "\n",
    "    #validation loss\n",
    "    #1. take the current theta, and do prediction with the validation set\n",
    "    yhat_val = X_val @ theta\n",
    "    #2. calculate the loss with y_val\n",
    "    val_loss = mse(yhat_val, y_val)\n",
    "    #3. finish\n",
    "    \n",
    "    #########early stopping###################\n",
    "    #1. if new val_loss is very close to old val_loss by 0.001, you stop everything ok!\n",
    "    if np.abs(old_val_loss - val_loss) < tolerance:\n",
    "        print(f'Stopped at epoch {i} - :-)')\n",
    "        break\n",
    "    #2. otherwise continue\n",
    "    old_val_loss = val_loss\n",
    "    \n",
    "    print(f\"Epoch: {i+1}  : {train_loss=:.3f} : {val_loss=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20266781, 0.95531753])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse=2.76\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/chaklam/Github/Machine-Learning/01 - Supervised/01 - Regression/code-along/Gradient Descent.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chaklam/Github/Machine-Learning/01%20-%20Supervised/01%20-%20Regression/code-along/Gradient%20Descent.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mse       \u001b[39m=\u001b[39m mse(  yhat_test , y_test  )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chaklam/Github/Machine-Learning/01%20-%20Supervised/01%20-%20Regression/code-along/Gradient%20Descent.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmse\u001b[39m=:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chaklam/Github/Machine-Learning/01%20-%20Supervised/01%20-%20Regression/code-along/Gradient%20Descent.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39massert\u001b[39;00m mse \u001b[39m>\u001b[39m \u001b[39m100\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "yhat_test = X_test @ theta\n",
    "mse       = mse(  yhat_test , y_test  )\n",
    "print(f\"{mse=:.2f}\")\n",
    "\n",
    "assert mse > 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0], y_train[0], X_train[1], y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. randomly create a sample\n",
    "chaky_test_case = np.array([ [1.5, 0.5] ])\n",
    "assert len(chaky_test_case.shape) == 2  #m, n\n",
    "\n",
    "#2. predict\n",
    "predict_chaky_test_case = chaky_test_case @ theta\n",
    "predict_chaky_test_case_int = float(predict_chaky_test_case)\n",
    "print(f\"Answer:  {predict_chaky_test_case_int: .2f}.  Does it satisfy you?\")\n",
    "\n",
    "#3. check with your instinct / ask expert whether is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume you have standardize your feature\n",
    "#feature 2 is more important\n",
    "    # 0.30 / (0.04 + 0.30)\n",
    "    \n",
    "#feature 1 is less important\n",
    "    # 0.04 / (0.04 + 0.030)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
