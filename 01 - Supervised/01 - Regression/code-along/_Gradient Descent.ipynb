{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = np.array([[1, 1], [2, 2], [2, 9], [1, 14]])\n",
    "X_train.shape #m, n\n",
    "\n",
    "y_train = np.array([3, 4, 10, 13])\n",
    "y_train.shape #m, \n",
    "\n",
    "X_val = np.array([[1.5, 2], [2, 3], [1, 9], [1, 13]])\n",
    "X_val.shape #m, n\n",
    "\n",
    "y_val = np.array([3, 4, 9.5, 13.5])\n",
    "y_val.shape #m, \n",
    "\n",
    "X_test = np.array([[2, 1], [1, 2], [2, 8], [2, 13]])\n",
    "X_test.shape #m, n\n",
    "\n",
    "y_test = np.array([2, 5, 9, 14])\n",
    "y_test.shape #m, \n",
    "\n",
    "# assert X_train.shape[1] == X_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling\n",
    "\n",
    "Imagine you do:\n",
    "1. imputation - cleaning\n",
    "2. scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for definitions\n",
    "m_train, n_train = X_train.shape\n",
    "m_val, n_val     = X_val.shape\n",
    "m_test, n_test   = X_test.shape\n",
    "num_epochs       = 50\n",
    "theta            = np.zeros(  (n_train,   )  )\n",
    "lr               = 0.001\n",
    "old_val_loss     = np.infty\n",
    "tolerance        = 0.06\n",
    "batch_size       = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(yhat, ytrue):\n",
    "    return ( (yhat - ytrue) ** 2  ).sum() / yhat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input, theta):\n",
    "    return input @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(input, yhat, ytrue):\n",
    "    return (input.T @ (yhat - ytrue) ) / input.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Running the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    10  : train_loss =  6.381 : val_loss=5.147\n",
      "Epoch:    20  : train_loss =  2.105 : val_loss=0.913\n",
      "Epoch:    30  : train_loss =  1.829 : val_loss=0.474\n",
      "Epoch:    40  : train_loss =  1.741 : val_loss=0.388\n",
      "Epoch:    50  : train_loss =  1.664 : val_loss=0.358\n"
     ]
    }
   ],
   "source": [
    "#1. loop according to epoch\n",
    "for i in range(num_epochs):  #0, 1, 2, 3, 4\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    \n",
    "    #mini-batch sampling:  take only a portion of X, and do everything else\n",
    "    #without replacement\n",
    "    for idx in range(0, X_train.shape[0], batch_size):\n",
    "        \n",
    "        X_train_mini = X_train[idx:idx+batch_size]\n",
    "        y_train_mini = y_train[idx:idx+batch_size]\n",
    "    \n",
    "        #2. predict\n",
    "        yhat_train = predict(X_train_mini, theta) # (m, n) x (n, 1) = (m, 1)  #<---same shape as y \n",
    "        \n",
    "        #3. gradient\n",
    "        grad = gradient(X_train_mini, yhat_train, y_train_mini)  #(n, m) @ (m, 1) = (n, 1)\n",
    "    \n",
    "        #4. update\n",
    "        theta = theta - lr * grad  # (n, 1) - (1) (n, 1) = (n, 1)\n",
    "        \n",
    "        total_train_loss +=  mse(yhat_train, y_train_mini)\n",
    "        \n",
    "    train_loss = total_train_loss / (X_train.shape[0] / batch_size)\n",
    "\n",
    "    #validation loss\n",
    "    #1. take the current theta, and do prediction with the validation set\n",
    "    yhat_val = X_val @ theta\n",
    "    #2. calculate the loss with y_val\n",
    "    val_loss = mse(yhat_val, y_val)\n",
    "    #3. finish\n",
    "    \n",
    "    #########early stopping###################\n",
    "    #1. if new val_loss is very close to old val_loss by 0.001, you stop everything ok!\n",
    "    diff = np.abs(old_val_loss - val_loss)\n",
    "    \n",
    "    # if diff < tolerance:\n",
    "    #     print(f'Stopped at epoch {i} - :-)')\n",
    "    #     #save your model right here!!!\n",
    "    #     filename = f\"chaky_model_{i}_{time.time():.0f}_lr.sav\"\n",
    "    #     pickle.dump(theta, open(filename, 'wb'))\n",
    "    #     break\n",
    "    # #2. otherwise continue\n",
    "    # old_val_loss = val_loss\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"Epoch: {i+1:5.0f}  : {train_loss =:7.3f} : {val_loss=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chaklam/Github/Machine-Learning/01 - Supervised/01 - Regression/code-along/Gradient Descent.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chaklam/Github/Machine-Learning/01%20-%20Supervised/01%20-%20Regression/code-along/Gradient%20Descent.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m load_theta \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "load_theta = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = X_test @ load_theta\n",
    "mse_      = mse(  yhat_test , y_test  )\n",
    "print(f\"{mse_= :.2f}\")\n",
    "\n",
    "assert mse_ < 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0], y_train[0], X_train[1], y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. randomly create a sample\n",
    "chaky_test_case = np.array([ [1.5, 0.5] ])\n",
    "assert len(chaky_test_case.shape) == 2  #m, n\n",
    "\n",
    "#2. predict\n",
    "predict_chaky_test_case = chaky_test_case @ theta\n",
    "predict_chaky_test_case_int = float(predict_chaky_test_case)\n",
    "print(f\"Answer:  {predict_chaky_test_case_int: .2f}.  Does it satisfy you?\")\n",
    "\n",
    "#3. check with your instinct / ask expert whether is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume you have standardize your feature\n",
    "#feature 2 is more important\n",
    "    # 0.30 / (0.04 + 0.30)\n",
    "    \n",
    "#feature 1 is less important\n",
    "    # 0.04 / (0.04 + 0.030)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
