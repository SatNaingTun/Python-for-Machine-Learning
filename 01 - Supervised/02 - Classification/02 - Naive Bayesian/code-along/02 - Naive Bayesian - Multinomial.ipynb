{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian - Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y|w) = \\frac{P(w|y)P(y)}{P(w)}\n",
    "$$\n",
    "\n",
    "$$ P(w_i \\in train \\mid y=k) = \\frac{count(w_i, k)}{\\sum_{i=1}^{n} count(w_i, k)} $$\n",
    "    \n",
    "Example:\n",
    "\n",
    "| | docID  | words in doc    | China?   |    \n",
    "|---:|:-------------|:-----------|:------|\n",
    "| Training set | 1  | Chinese Beijing Chinese       | Yes   |\n",
    "|  | 2  | Chinese Chinese Shanghai    | Yes  |\n",
    "|  | 3  | Chinese Macao    | Yes   |\n",
    "|  | 4  | Tokyo Japan Chinese   | No   |\n",
    "| Test set | 5  | Chinese Chinese Chinese Tokyo Japan    | ?   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace smoothing\n",
    "\n",
    "$$ P(w_i \\in train \\mid y=k) = \\frac{count(w_i, k) + 1}{\\sum_{i=1}^{n} count(w_i, k) + n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors\n",
    "\n",
    "$$P(y = k) = \\frac{\\Sigma_{i=1}^{m}1(y=k)}{m} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total likelihood\n",
    "\n",
    "$$ P(w \\in test \\mid y=k) = \\prod_{i=1}^{n} P(w_i \\mid y=k)^{\\text{freq of }w_i}$$\n",
    "    \n",
    "## Probability\n",
    "\n",
    "$$P (y = k \\mid w \\in test) = P(y=k)\\prod_{i=1}^{n} P(w_i \\mid y=k)^{\\text{freq of }w_i}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log probability\n",
    "   \n",
    "$$P (y = k \\mid w \\in test) = \\log \\ P(y=k) + \\sum_{i=1}^{n} (\\text{freq of }w_i) * \\log \\ p(w_i \\mid y=k)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data = fetch_20newsgroups()\n",
    "data.target_names\n",
    "\n",
    "categories = ['talk.religion.misc', 'soc.religion.christian',\n",
    "              'sci.space', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print(train.data[0]) #first 300 words\n",
    "print(\"Target: \", train.target[0])  #start with 1, soc.religion.christian\n",
    "\n",
    "#transform our X to frequency data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train.data)\n",
    "X_test = vectorizer.transform(test.data)\n",
    "X_test = X_test.toarray()  #vectorizer gives us a sparse matrix; convert back to dense matrix\n",
    "\n",
    "y_train = train.target\n",
    "y_test = test.target\n",
    "\n",
    "print(\"X_train: \", X_train[0])\n",
    "print(\"y_train: \", y_train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculating likelihood anrd prior"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Let's use them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
